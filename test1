ğŸ“… Week 1 â€” Project Setup & Access

Set up Dataiku project and folder structure

Secure access approvals for all document repositories

Gather compliance checklists (DOD, Broker Deal, LCM)

Gather regulatory/supporting documents (Compliance Handling, PAMS, etc.)

Define row extraction rules with Audit QA (what constitutes a row, how multi-page text is handled)

Identify bank-approved LLM + embedding model options

ğŸ“… Week 2 â€” Document Ingestion & Preprocessing

Upload all documents into Dataiku managed folders

Perform text extraction: PDF, DOCX, XLSX, PPTX, MSG

Normalize text (encoding cleanup, whitespace, structural formatting)

Extract tables into structured datasets

Convert each table row into a â€œunit of evaluationâ€ dataset

Preserve metadata (doc name, page no., section, row index)

Run initial quality checks on extracted text

ğŸ“… Week 3 â€” Embedding Model Configuration

Configure bank-approved embedding model in Dataiku
(Azure OpenAI embedding, SBERT internal model, or approved alternative)

Determine chunking strategy:

Chunk size

Overlap

Section-level segmentation

Validate embedding outputs on sample regulatory text

Finalize vector schema (embedding + text + metadata)

ğŸ“… Week 4 â€” Vector Database Creation & Indexing

Create vector store using bank-approved solution:

FAISS in Dataiku Python environment, or

Elastic/OpenSearch vector index, or

Azure Cognitive Search private instance

Store embeddings and metadata for all supporting documents

Implement indexing pipeline (batch or incremental)

Validate retrieval speed, accuracy, and semantic grouping

Ensure indexing logs & access controls are enabled for audit trail

ğŸ“… Week 5 â€” Retrieval Layer (RAG)

Implement retrieval function for regulatory alignment

Define retrieval logic: top_k, similarity threshold, fallback strategies

Validate retrieval for sample requirements and ensure relevance

Add checks to ensure retrieval uses only approved content

Log retrieved chunks with doc_id + section_id for traceability

Fine-tune retrieval to avoid noise or irrelevant segments

ğŸ“… Week 6 â€” LLM Evaluation Logic (Core Reasoning)

Build controlled prompts for:

Regulatory alignment

Completeness

Citation presence

Business rules (â€œModel Agnostic â†’ Return Plan = Noneâ€)

Enforce temperature=0, deterministic output

Define JSON schema for model output

Run evaluation on baseline rows

Begin tuning prompts based on initial results

Integrate retrieval + evaluation + JSON output into a Dataiku Python recipe

ğŸ“… Week 7 â€” Validation Layer + Logging

Build secondary validation pass (LLM or rules-based)

Validator checks:

Citation validity (must exist in retrieved chunks)

Alignment defensibility

Completeness justification

JSON schema correctness

Add confidence scoring and rule violation flags

Implement full logging:

Prompt

Retrieved chunks

LLM output

Model version

Timestamp

SME Review Round #1: Early feedback on evaluation quality

ğŸ“… Week 8 â€” UI Development on Dataiku (Dashboard/Webapp)

Build user-facing Audit QA dashboard

Features:

Document selector

Summary of results (Aligned / Gaps / Skipped / Violations)

Row-level drilldown:

Requirement text

Assessment text

Retrieved citations

Modelâ€™s evaluation

Export options for detailed analysis

Add severity filters, search, and highlighting

Conduct usability testing with Audit QA users

ğŸ“… Week 9 â€” Reviewer Pack Development (Word/PDF)

Build automation to generate final Reviewer Pack

Include:

Summary sheet

Row-by-row verdicts

Reasons and regulatory citations

Rule violations

Skipped rows + reasons

Format pack according to Audit QAâ€™s documentation style

Generate test packs for 2â€“3 checklists

SME Review Round #2 for accuracy and format feedback

ğŸ“… Week 10 â€” Extended Testing (Large Documents, Multi-Table)

Run system on full-scale checklists

Validate performance on rows with 2â€“4 pages of text

Tune retrieval noise, overlap, and chunk sizing

Improve prompts based on complex requirements

Ensure consistent outputs across repeated runs

Refine UI based on reviewer feedback

ğŸ“… Week 11 â€” Stabilization & Governance Readiness

Consolidate logs, metadata, and evaluation datasets

Ensure all components meet Responsible AI and Model Risk guidelines

Test edge cases:

Missing supporting docs

Very long text rows

Empty responses

Validate deterministic behavior at scale

Prepare draft governance documentation:

Architecture

Controls

Logging

Data lineage

Model selection

Risk mitigations

Week 12 â€” Final Packaging & POC Demo

Finalize Reviewer Pack for sample checklist(s)

Prepare POC summary report (business, technical, benefits, risks)

Conduct full end-to-end demo for Audit QA & leadership

Present recommendations for next phase (Pilot â†’ Scale)

Package project artifacts inside Dataiku for handover

Document all learnings + future roadmap
